{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import icbhi-preprocessing-v2 and icbhi-extraction-v2 data before running","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom matplotlib.legend_handler import HandlerLine2D\nimport matplotlib.cm as cm\nimport pandas as pd\n\n# Not immediately usable with this dataset as files contain 24-bit data\nfrom scipy.io import wavfile\nfrom scipy.io.wavfile import read, write\n\nimport IPython.display as ipd\nfrom IPython.display import Audio\nfrom numpy.fft import fft, ifft\n\nimport librosa as lr\nimport librosa.display\n\nimport os\nimport pickle\nfrom glob import glob\n\nimport seaborn as sns\n\nfrom scipy import signal as sig\nfrom scipy.signal import butter, lfilter, sosfilt\nfrom tqdm import tqdm\nimport pywt\nimport random\nimport skimage.data\nfrom skimage.restoration import denoise_wavelet\nfrom pywt import swt\nimport time as tm\nimport collections\n\n# if ('pydub' in globals()) == False:\n#   !pip install pydub\n# from pydub import AudioSegment\n# from pydub.utils import make_chunks\n\n\n# LT-06-24: import io to save intermediate outputs; use \"as\" to shorten module.function name as \"spio\"\nimport scipy.io as spio\n\n\n# LT-06-24: install modules if not found \n# if ( 'umap' in globals() ) == False: \n#   !pip install umap-learn\n\nimport umap.umap_ as umap\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, minmax_scale\nfrom sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import silhouette_samples, silhouette_score, classification_report, confusion_matrix, accuracy_score, plot_confusion_matrix, roc_curve\n\nprint('Importing done')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T18:27:18.921476Z","iopub.execute_input":"2022-02-28T18:27:18.92179Z","iopub.status.idle":"2022-02-28T18:27:39.754093Z","shell.execute_reply.started":"2022-02-28T18:27:18.921711Z","shell.execute_reply":"2022-02-28T18:27:39.753359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature & Class Data","metadata":{}},{"cell_type":"code","source":"class_list = np.load(\"../input/icbhi-preprocessing-v3/class_list.npy\")\ndirectory = '../input/icbhi-extraction-v3/' \nnsamples = len(class_list)\nfeatures = np.zeros( ( nsamples, 97573) )\nclasses = np.zeros( nsamples ).astype(int)\n\nfor d in range( 0, nsamples):\n    try: # quick hack to read some        \n        classes[d] = class_list[d] \n        features[d] = np.load(directory + str(d) + '_features.npy')\n    except:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-02-28T18:27:39.75572Z","iopub.execute_input":"2022-02-28T18:27:39.755915Z","iopub.status.idle":"2022-02-28T18:28:52.890193Z","shell.execute_reply.started":"2022-02-28T18:27:39.755892Z","shell.execute_reply":"2022-02-28T18:28:52.888777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Subsetting","metadata":{}},{"cell_type":"code","source":"normals = np.where(classes == 0)[0].tolist()\ncrackles = np.where(classes == 1)[0].tolist()\nwheezes = np.where(classes == 2)[0].tolist()\ncracklewheezes = np.where(classes == 3)[0].tolist()\n\ni_subsets = []\nn = 500 # samples per class\nseeds = [3319, 1339, 136]\nfor i, s in enumerate(seeds):\n    random.seed(s)\n    set1 = random.sample(normals, n)\n    set2 = random.sample(crackles, n)\n    set3 = random.sample(wheezes, n)\n    set4 = random.sample(cracklewheezes, n)\n    i_subsets.append(np.hstack((set1, set2, set3, set4)))\n    \ndef get_feature_set(l, features):\n    f = np.zeros((len(l), 97573))\n    for i, index in enumerate(l):\n        f[i] = features[index]\n    return f\n\nfeature_sets = []\nfor l in i_subsets:\n    feature_sets.append(get_feature_set(l, features))\n\nclass_set = [0] * n\nclass_set.extend([1] * n)\nclass_set.extend([2] * n)\nclass_set.extend([3] * n)\n    \nfeature_sets","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:35:49.459374Z","iopub.execute_input":"2021-12-15T21:35:49.45992Z","iopub.status.idle":"2021-12-15T21:35:53.64622Z","shell.execute_reply.started":"2021-12-15T21:35:49.459861Z","shell.execute_reply":"2021-12-15T21:35:53.645225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(normals))\nprint(len(crackles))\nprint(len(wheezes))\nprint(len(cracklewheezes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-Nearest Neighbours","metadata":{}},{"cell_type":"code","source":"m = min(len(normals), len(crackles), len(wheezes), len(cracklewheezes))\n\nnormals = normals[:m]\ncrackles = crackles[:m]\nwheezes = wheezes[:m]\ncracklewheezes = cracklewheezes[:m]\nbalanced_set = np.hstack((normals, crackles, wheezes, cracklewheezes))\n\nbalanced_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_features = np.zeros((len(balanced_set), 97573))\nfor i, index in enumerate(balanced_set):\n    balanced_features[i] = features[index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_classes = [0] * m\nbalanced_classes.extend([1] * m)\nbalanced_classes.extend([2] * m)\nbalanced_classes.extend([3] * m)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 75% train, 25% test\nX_train, X_test, y_train, y_test = train_test_split(balanced_features, balanced_classes, random_state=321)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=4)\nknn.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = knn.predict(X_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(knn, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dry Run","metadata":{}},{"cell_type":"code","source":"expert = '../input/dryrun/9002_expert/'\nexpertnames = [s.split('.')[0] for s in os.listdir(path = expert) if '.wav' in s]\nnonexpert = '../input/dryrun/9002_nonexpert/'\nnonexpertnames = [s.split('.')[0] for s in os.listdir(path = nonexpert) if '.wav' in s]\nvolunteer = '../input/dryrun/9002_volunteer/'\nvolunteernames = [s.split('.')[0] for s in os.listdir(path = volunteer) if '.wav' in s]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get waveforms\ndef signal_and_sr(filename, root):\n    name = root + filename + '.wav'\n    signal, sr = lr.load(name, sr=None)\n    return signal, sr\n\ndef waveforms(files, root):\n  signals = []\n  srs = []\n  for name in files:\n    (sig, sr) = signal_and_sr(name, root) # signal is an array with (sr * duration) values\n    # if (len(sig) % 2) == 0: # signal array must be an even number of values for MODWT\n    signals.append(sig)\n    srs.append(sr)\n  return signals, srs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( expert )\nexpertnames\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_sigs, exp_srs = waveforms(expertnames, expert)\nnonexp_sigs, nonexp_srs = waveforms(nonexpertnames, nonexpert)\nvol_sigs, vol_srs = waveforms(volunteernames, volunteer)\nfor i, s in enumerate(exp_sigs):\n    print(lr.get_duration(y = s, sr = exp_srs[i]))\nfor i, s in enumerate(nonexp_sigs):\n    print(lr.get_duration(y = s, sr = nonexp_srs[i]))\nfor i, s in enumerate(vol_sigs):\n    print(lr.get_duration(y = s, sr = vol_srs[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(samples, files, sr=4000, max_length=6, new_sr=8000, lowcut=150, highcut=2000, order=5):\n    \"\"\"\n    1) Add zeros to slices so that they are the same length or reduce their length to the maximum length\n    2) Apply bandpass filters and resample to 8000Hz\n    3) Scale signal amplitudes to be between -1 and 1\n    \"\"\"\n    # Zero-padding\n    padded_slices = []\n    for i, signal in enumerate(samples):\n        if (lr.get_duration(signal, sr=sr) <= 15.0) & (lr.get_duration(signal, sr=sr) > 10.0):\n            slices = [signal[:int(round(5 * sr))], signal[int(round(5 * sr)):int(round(10 * sr))], signal[int(round(10 * sr)):]]\n            for s in slices:\n                padded_slices.append(lr.util.pad_center(s, max_length*sr))\n        elif (lr.get_duration(signal, sr=sr) <= 10.0) & (lr.get_duration(signal, sr=sr) > 5.0):\n            slices = [signal[:int(round(5 * sr))], signal[int(round(5 * sr)):]]\n            for s in slices:\n                padded_slices.append(lr.util.pad_center(s, max_length*sr))\n        else:\n            padded_slices.append(lr.util.pad_center(signal, max_length*sr))\n    \n    # Bandpass filter & resample (technically should be resampling after filtering but this causes a bug...)\n    processed = np.zeros((len(padded_slices), (max_length*new_sr)))\n    for i, signal in enumerate(padded_slices):\n        resample = lr.resample(signal, sr, new_sr)\n        y = butter_bandpass_filter(resample, lowcut, highcut, new_sr, order) # dataset contains more than one sr - 44100, 4000 and 10000; Pramono et al. recommend 8000Hz as respiratory sound information is bandlimited up to 2000Hz..?\n        processed[i, :len(y)] = y\n    \n    # Amplitude scaling to [-1, 1]\n    for i, signal in enumerate(processed):\n        peak = max(abs(signal))\n        dB = 0\n\n        amp_lin = 10**(dB/20)\n        z = amp_lin*(1/peak)*signal\n        \n        processed[i, :len(z)] = z\n        \n    return processed\n\ndef butter_bandpass_filter(data, lowcut, highcut, sr, order):\n    sos = butter_bandpass(lowcut, highcut, sr, order=order)\n    y = sosfilt(sos, data)\n    return y\n    \ndef butter_bandpass(lowcut, highcut, sr, order):\n    nyq = 0.5 * sr\n    low = lowcut / nyq\n    high = highcut / nyq\n    sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n    return sos","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepro_exp = preprocessing(exp_sigs, expertnames)\nprepro_nonexp = preprocessing(nonexp_sigs, nonexpertnames)\nprepro_vol = preprocessing(vol_sigs, volunteernames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract(signal, sr=8000):\n    \"\"\"\n    signal: slice that has already undergone preprocessing\n    sr: sampling rate of slice\n    \"\"\"\n    # Spectrograms\n    stft = lr.stft(signal)\n    spec = lr.amplitude_to_db(abs(stft))\n    \n    # Mel-cepstral frequency coefficients\n    mfcc = lr.feature.mfcc(signal, sr, n_mfcc=13)\n    \n    # Wavelet transform using Baubechies with 4 vanishing moments\n    modwt = np.array(pywt.dwt(signal, 'db4', mode='zero'))\n    # Zero crossing rate\n    wt_zcr = len(np.nonzero(np.diff(np.array(modwt) > 0))[0])\n    \n    return spec, mfcc, wt_zcr\n\ndef feature_extraction(preprocessed_slices):\n    feature_set = np.zeros((len(preprocessed_slices), 97573))\n    for i, signal in enumerate(preprocessed_slices):\n        # Extract\n        spec, mfcc, wt_zcr = extract(signal)\n        \n        # Reshape\n        a,b = spec.shape\n        c,d = mfcc.shape\n        spec = spec.reshape((a*b))\n        mfcc = mfcc.reshape((c*d))\n        features = np.hstack((spec, mfcc, wt_zcr))\n        feature_set[i] = features\n        \n    return feature_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( len(exp_sigs), prepro_exp.shape ) # 13 x 3 ?\nprint( len(nonexp_sigs), prepro_nonexp.shape ) # 13 x 3 = 39 \nprint( len(vol_sigs), prepro_vol.shape ) # 6 x 3 = 18 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_features = feature_extraction(prepro_exp)\nnonexp_features = feature_extraction(prepro_nonexp)\nvol_features = feature_extraction(prepro_vol)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_pred = knn.predict(exp_features)\nnonexp_pred = knn.predict(nonexp_features)\nvol_pred = knn.predict(vol_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(exp_pred)\nprint(nonexp_pred)\nprint(vol_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/input/knn_4.pkl', 'wb') as f:\n    pickle.dump(knn, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"expertnames","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef write_to_pkl( file, dic ):    \n    from pickle import dump        \n    f=open( file + '.pkl' , 'wb')      \n    dump( dic, f)\n    f.close()\n    \n    \n    \ndef read_from_pkl( file ):    \n    from pickle import load    \n    file = file.replace( '.pkl','')    \n    file = open( file + '.pkl', 'rb')    \n    try:\n        dat = load( file )\n    except:\n        dat = load( file, encoding='latin1')\n    return dat\n\nknn4=read_from_pkl('knn_4.pkl')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# knn4's predictions are reproducible \n\nexp_pred_knn4 = knn4.predict(exp_features)\nexp_pred_knn4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# prepro_exp = preprocessing(exp_sigs, expertnames)\n\nexpertnames\nexp_sigs[1].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot( exp_features[1,:-1] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"m = 4 # Accuracies per class\nKNNs = {}\nacc = np.zeros( (len(feature_sets), m) )\nknn = KNeighborsClassifier(n_neighbors=8) # Change n_neighbors to desired k\n\nfor i, s in enumerate(feature_sets):\n    X_train, X_test, y_train, y_test = train_test_split(s, class_set, random_state=321)\n    KNNs[i] = knn.fit(X_train, y_train)\n    y_pred = KNNs[i].predict(X_test)\n    matrix = confusion_matrix(y_test, y_pred)\n    acc[i] = matrix.diagonal()/matrix.sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T19:49:11.03493Z","iopub.execute_input":"2021-12-15T19:49:11.035294Z","iopub.status.idle":"2021-12-15T19:53:06.079742Z","shell.execute_reply.started":"2021-12-15T19:49:11.035259Z","shell.execute_reply":"2021-12-15T19:53:06.078601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"execution":{"iopub.status.busy":"2021-12-15T19:53:06.082586Z","iopub.execute_input":"2021-12-15T19:53:06.083171Z","iopub.status.idle":"2021-12-15T19:53:06.09153Z","shell.execute_reply.started":"2021-12-15T19:53:06.083128Z","shell.execute_reply":"2021-12-15T19:53:06.090389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"m = 4 # Accuracies per class\nDTs = {}\nacc = np.zeros( (len(feature_sets), m) )\ndt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=9)\n\nfor i, s in enumerate(feature_sets):\n    X_train, X_test, y_train, y_test = train_test_split(s, class_set, random_state=321)\n    DTs[i] = dt.fit(X_train, y_train)\n    y_pred = DTs[i].predict(X_test)\n    matrix = confusion_matrix(y_test, y_pred)\n    acc[i] = matrix.diagonal()/matrix.sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T20:29:31.520255Z","iopub.execute_input":"2021-12-15T20:29:31.520597Z","iopub.status.idle":"2021-12-15T20:41:12.976853Z","shell.execute_reply.started":"2021-12-15T20:29:31.520557Z","shell.execute_reply":"2021-12-15T20:41:12.975471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"execution":{"iopub.status.busy":"2021-12-15T20:41:12.979581Z","iopub.execute_input":"2021-12-15T20:41:12.979935Z","iopub.status.idle":"2021-12-15T20:41:12.988052Z","shell.execute_reply.started":"2021-12-15T20:41:12.97989Z","shell.execute_reply":"2021-12-15T20:41:12.987181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_depths = np.linspace(1, 20, 20, endpoint=True)\nX_train, X_test, y_train, y_test = train_test_split(feature_sets[0], class_set, random_state=321)\n\ntrain = []\ntest = []\nfor depth in max_depths:\n    dt = DecisionTreeClassifier(max_depth=depth)\n    dt.fit(X_train, y_train)\n    \n    train_pred = dt.predict(X_train)\n    \n    matrix = confusion_matrix(y_train, train_pred)\n    acc = np.mean(matrix.diagonal()/matrix.sum(axis=1))\n    train.append(acc)\n    \n    y_pred = dt.predict(X_test)\n    \n    matrix = confusion_matrix(y_test, y_pred)\n    acc = np.mean(matrix.diagonal()/matrix.sum(axis=1))\n    test.append(acc)\n    \nline1, = plt.plot(max_depths, train, label=\"Train Accuracy\")\nline2, = plt.plot(max_depths, test, label=\"Test Accuracy\")\n    \nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel(\"Average Classwise Accuracy\")\nplt.xlabel(\"Tree Depth\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:38:11.191498Z","iopub.execute_input":"2021-12-15T21:38:11.192223Z","iopub.status.idle":"2021-12-15T22:04:09.328398Z","shell.execute_reply.started":"2021-12-15T21:38:11.192179Z","shell.execute_reply":"2021-12-15T22:04:09.327247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}